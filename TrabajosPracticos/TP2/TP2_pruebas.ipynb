{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Transformer (ViT)\n",
    "\n",
    "El Vision Transformer (ViT), propuesto por Dosovitskiy et al. (2020), utiliza una arquitectura basada en Transformers para tareas de visión por computadora. A diferencia de las CNN, el ViT aplica **Multi-Head Self-Attention (MHSA)** para modelar relaciones globales entre partes de la imagen.\n",
    "\n",
    "## Arquitectura\n",
    "\n",
    "El ViT divide las imágenes en **patches** y las convierte en una secuencia de vectores de características (embeddings), que luego se procesan mediante capas Transformer. A continuación, se aplica el mecanismo de self-attention para modelar las relaciones entre estos patches.\n",
    "\n",
    "- **Embeddings**: Cada parche se aplana y se proyecta en un espacio de mayor dimensión.\n",
    "- **Positional Encoding**: Se agrega un embebido posicional para cada parche, permitiendo que el modelo capture las posiciones espaciales.\n",
    "---\n",
    "## ¿Cómo funciona el Self-Attention en ViT?\n",
    "\n",
    "Cada uno de los parches se considera un token similar a las palabras en el procesamiento del lenguaje natural (NLP).\n",
    "En el mecanismo de Self-Attention, cada uno de estos tokens (parches) puede interactuar con los demás tokens. Para hacerlo, el modelo calcula tres vectores para cada token: \n",
    "\n",
    "- **Query:** Representa qué está buscando el token.\n",
    "\n",
    "- **Key:** Representa una descripción de los demás tokens.\n",
    "\n",
    "- **Value:** Es la información que tiene cada token y que podría ser relevante para otros tokens.\n",
    "\n",
    "Luego, se calculan las similitudes entre el *Query* de un token y el *Key* de todos los demás tokens, lo que genera una \"puntuación de atención\". Esta puntuación determina cuánta atención debe prestar un token a otros. El valor *Value* de cada token se pondera según esta puntuación, lo que permite que un token integre información de todo el resto de la imagen.\n",
    "\n",
    "Este mecanismo es lo que permite que cada token (parche) en una imagen entienda no solo lo que está ocurriendo en su área local, sino también pueda considerar qué está sucediendo en otras partes de la imagen. \n",
    "\n",
    "La fórmula utilizada para calcular la atención es:\n",
    "\n",
    "$$\n",
    "\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- **$Q$ (queries)**, **$K$ (keys)**, y **$V$ (values)** son las proyecciones lineales de los embeddings de los patches.\n",
    "- **$d_k$** es la dimensionalidad de las proyecciones, usada para escalar el producto punto y estabilizar el entrenamiento.\n",
    "\n",
    "Este proceso se aplica en múltiples cabezas, lo que permite al modelo aprender distintas representaciones.\n",
    "\n",
    "El mecanismo de self-attention utiliza las proyecciones:\n",
    "\n",
    "$$Q = XW_Q, \\quad K = XW_K, \\quad V = XW_V$$\n",
    "\n",
    "Donde $X$ es el input y $W_Q$, $W_K$, y $W_V$ son matrices de pesos aprendidos.\n",
    "\n",
    "Después de aplicar el mecanismo de Self-Attention, los tokens se actualizan, ya que ahora tienen información de los demás tokens. Este proceso se repite varias veces en distintas capas de atención, profundizando la interacción entre los parches.\n",
    "\n",
    "Salida Final: Después de aplicar múltiples capas de Self-Attention, el modelo agrupa los tokens procesados para predecir la clase de la imagen o realizar otras tareas de visión.\n",
    "\n",
    "\n",
    "![Vision Transformer](vit_gif.gif)\n",
    "\n",
    "*Crédito: [lucidrains](https://github.com/lucidrains/vit-pytorch)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tareas:\n",
    "\n",
    "1. **Implementar la arquitectura de un Vision Transformer** \n",
    "\n",
    "2. **Ingresar y ajustar los parametros del modelo**\n",
    "\n",
    "3. **Probar diferentes técnicas de data augmentation** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo:  cuda\n",
      "Torch version:  2.5.1+cu124\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "from trainer import Trainer\n",
    "\n",
    "\n",
    "\n",
    "device =  'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "print('Dispositivo: ',device)\n",
    "print('Torch version: ',torch.__version__)\n",
    "\n",
    "# La configuración, carga y preprocesamiento\n",
    "class ConfigPreprocess:\n",
    "    def __init__(self, device: str, img_path: str, img_size: int, patch_size: int):\n",
    "        self.device = device\n",
    "        self.img_path = img_path\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.test_img = self.load_image()\n",
    "\n",
    "    def load_image(self):\n",
    "        return TF.to_tensor(Image.open(self.img_path).resize((self.img_size, self.img_size))).unsqueeze(0).to(self.device)\n",
    "\n",
    "    def extract_patches(self, image: Tensor) -> Tensor:\n",
    "        patches = image.unfold(1, self.patch_size, self.patch_size).unfold(2, self.patch_size, self.patch_size)\n",
    "        patches = patches.contiguous().view(image.shape[0], -1, self.patch_size, self.patch_size)\n",
    "        return patches\n",
    "    \n",
    "\n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, img_size: int, patch_size: int, in_channels: int = 3, embed_dim: int = 8):\n",
    "        super(PatchEmbedding, self).__init__()\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = (img_size // patch_size) ** 2\n",
    "        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)  # (B, embed_dim, H/patch_size, W/patch_size)\n",
    "        x = x.flatten(2)  # (B, embed_dim, num_patches)\n",
    "        x = x.transpose(1, 2)  # (B, num_patches, embed_dim)\n",
    "        # print('ClassPatchEmb Outputshape:', x.shape)\n",
    "        return x\n",
    "\n",
    "class PositionalEncodingLearned(nn.Module):\n",
    " \n",
    "    def __init__(self, img_size: int, patch_size: int, embed_dim):\n",
    "        super(PositionalEncodingLearned, self).__init__()\n",
    "        self.num_patches = (img_size // patch_size) ** 2\n",
    "        self.embed_dim = embed_dim\n",
    "        scale = embed_dim ** -0.5\n",
    "        self.pos_encoding = nn.Parameter(torch.randn(self.num_patches, embed_dim) * scale).unsqueeze(0).to(device)\n",
    "\n",
    "    \n",
    "    # def create_positional_encoding_learned(self, num_patches, embed_dim):\n",
    "    #     scale = embed_dim ** -0.5\n",
    "    #     pos_encoding = nn.Parameter(torch.randn(num_patches, embed_dim) * scale)\n",
    "    #     return pos_encoding.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "                \n",
    "        x = x + self.pos_encoding\n",
    "        # print('ClassPosEncLer Outputshape:', x.shape)\n",
    "        return x\n",
    "        \n",
    "\n",
    "\n",
    "# Parámetros\n",
    "img_path = \"raccoon.jpg\"\n",
    "img_size = 900\n",
    "patch_size = 64\n",
    "embed_dim = 8\n",
    "patch_idx = 0  # El índice del parche para el cual queres visualiizar la codificación posicional\n",
    "\n",
    "# Preprocesamiento\n",
    "config = ConfigPreprocess(device,img_path, img_size, patch_size)\n",
    "\n",
    "# Extracción de parches y visualización\n",
    "patches = config.extract_patches(config.test_img.squeeze(0))\n",
    "\n",
    "# Generación de embeddings\n",
    "embedded_patches = PatchEmbedding(img_size, patch_size, 3, embed_dim).to(config.device)\n",
    "patches = embedded_patches(config.test_img)\n",
    "\n",
    "# Codificación posicional\n",
    "\n",
    "num_patches = (img_size // patch_size) ** 2\n",
    "try:\n",
    "    positional_encoding = PositionalEncodingLearned(img_size, patch_size, embed_dim).to(config.device)\n",
    "    pos_embeddings = positional_encoding(patches)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Revise la existencia de la función PositionalEncodingLearned. Se produjo error durante la compilación: \\n {e}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 900, 900])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.test_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, embed_dim: int, num_heads: int, ff_dim: int, num_layers: int, batch_first:bool, dropout=0.1):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dim_feedforward=ff_dim, dropout=dropout,bias= False, batch_first=batch_first)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        output = self.transformer_encoder(x)\n",
    "        # print('ClassTransEncod Outputshape:', output.shape)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Transformer\n",
    "Model\n",
    "> \n",
    "```ViT-Base ViT-Large ViT-Huge\n",
    "    Layers Hidden size D 12 768\n",
    "    24 1024 32 1280\n",
    "    MLP size Heads\n",
    "    Params\n",
    "    3072 12 86M 4096 16 307M 5120 16 632M\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisionTransformer(nn.Module):\n",
    "    '''\n",
    "    Aca tiene que ir la arquitectura de VIT\n",
    "    \n",
    "    img_size=      ,\n",
    "    patch_size=    ,\n",
    "    embed_dim=     , \n",
    "    num_heads=     , \n",
    "    ff_dim=        , \n",
    "    num_layers=    , \n",
    "    dropout=       ,\n",
    "    batch_first=True\n",
    "\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, img_size, patch_size, embed_dim, num_heads, ff_dim, num_layers, dropout, batch_first, num_classes):\n",
    "        super(VisionTransformer,self).__init__()\n",
    "        num_patches = (img_size // patch_size) ** 2\n",
    "        self.patch_embedding = PatchEmbedding(img_size, patch_size, 3, embed_dim)\n",
    "        self.positional_encoding_learned = PositionalEncodingLearned(img_size, patch_size, embed_dim)\n",
    "        self.transformer_encoder = TransformerEncoder(embed_dim, num_heads, ff_dim, num_layers, batch_first, dropout)        \n",
    "        self.ffnet1 = nn.Linear(num_patches*embed_dim, ff_dim)\n",
    "        self.ffnet2 = nn.Linear(ff_dim, 128)\n",
    "        self.ffnet3 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        output = self.patch_embedding(x)\n",
    "        output = self.positional_encoding_learned(output)\n",
    "        output = self.transformer_encoder(output)\n",
    "        output = self.ffnet1(output.flatten(1))\n",
    "        output = F.relu(output)\n",
    "        output = self.ffnet2(output)\n",
    "        output = F.relu(output)\n",
    "        output = self.ffnet3(output)\n",
    "        # output = nn.functional.softmax(output, dim=1)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 32, 32])\n",
      "torch.Size([2, 4, 8])\n",
      "number of patches: 196\n",
      "torch.Size([2, 4, 8])\n",
      "torch.Size([2, 4, 8])\n",
      "torch.Size([2, 1024])\n",
      "torch.Size([2, 10])\n",
      "tensor([[-0.5974, -0.0063,  0.3700, -0.1490, -0.2789, -0.1986,  0.2220, -0.3610,\n",
      "          0.8197,  0.2218],\n",
      "        [ 0.1872, -0.1898,  0.1228, -0.6346,  0.2534, -0.4643, -0.2101, -0.4433,\n",
      "          0.5316, -0.1295]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.0505, 0.0912, 0.1329, 0.0791, 0.0695, 0.0753, 0.1146, 0.0640, 0.2084,\n",
      "         0.1146],\n",
      "        [0.1250, 0.0858, 0.1172, 0.0550, 0.1336, 0.0652, 0.0840, 0.0666, 0.1765,\n",
      "         0.0911]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn was passed bias=False\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "src = torch.rand(2, 3, 32, 32)\n",
    "# src = config.test_img.to('cpu')\n",
    "print(src.shape)\n",
    "\n",
    "imgsize = 32\n",
    "patchsize = 16\n",
    "inchannels = 3\n",
    "embbeddim = 8\n",
    "numheads = 8\n",
    "ffdim = 1024\n",
    "numlayers = 6\n",
    "numclasses = 10\n",
    "\n",
    "patch_embedding = PatchEmbedding(imgsize, patchsize, inchannels, embbeddim)\n",
    "paso1 = patch_embedding(src)\n",
    "print(paso1.shape)\n",
    "\n",
    "numpatches = (imgsize // patchsize) ** 2\n",
    "print('number of patches:', num_patches)\n",
    "\n",
    "positional_encoding_learned = PositionalEncodingLearned(imgsize, patchsize, embbeddim)\n",
    "paso2 = positional_encoding_learned(paso1.to(device))\n",
    "print(paso2.shape)\n",
    "\n",
    "transformer_encoder = TransformerEncoder(embbeddim, numheads, ffdim, numlayers, True, 0.1)\n",
    "paso3 = transformer_encoder(paso2.to('cpu'))\n",
    "print(paso3.shape)\n",
    "\n",
    "ffnet1 = nn.Linear(numpatches*embbeddim, ffdim)\n",
    "paso4 = ffnet1(paso3.flatten(1))\n",
    "print(paso4.shape)\n",
    "\n",
    "ffnet2 = nn.Linear(ffdim, numclasses)\n",
    "paso5 = ffnet2(paso4)\n",
    "print(paso5.shape)\n",
    "print(paso5)\n",
    "\n",
    "paso6 = nn.functional.softmax(paso5, dim=1)\n",
    "print(paso6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paso3.flatten(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "16\n",
      "torch.Size([2, 3, 32, 32])\n",
      "number of patches: 4\n",
      "torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "src = torch.rand(2, 3, 32, 32).to(device)\n",
    "# src = config.test_img\n",
    "imgsize = 900\n",
    "imgsize = src.shape[2]\n",
    "print(imgsize)\n",
    "\n",
    "patchsize = 100\n",
    "patchsize = imgsize // 2\n",
    "print(patchsize)\n",
    "\n",
    "inchannels = 3\n",
    "embbeddim = 8\n",
    "numheads = 8\n",
    "ffdim = 1024\n",
    "numlayers = 6\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(src.shape)\n",
    "num_patches = (imgsize // patchsize) ** 2\n",
    "print('number of patches:', num_patches)\n",
    "\n",
    "todo = VisionTransformer(\n",
    "    img_size=imgsize,\n",
    "    patch_size=patchsize,\n",
    "    embed_dim=embbeddim, \n",
    "    num_heads=numheads, \n",
    "    ff_dim=ffdim, \n",
    "    num_layers=numlayers, \n",
    "    dropout=0.1,\n",
    "    batch_first=True,\n",
    "    num_classes=10\n",
    ").to(device)\n",
    "\n",
    "pasos_completos = todo(src)\n",
    "print(pasos_completos.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define transformations for the input data\n",
    "transform = transforms.Compose([\n",
    "    #transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomResizedCrop((32, 32), scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.49139968, 0.48215841, 0.44653091], [0.24703223, 0.24348513, 0.26158784]),\n",
    "    #transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load your dataset\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset[3][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3072)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ver dentro de un batch\n",
    "batch1 = unpickle('./data/cifar-10-batches-py/data_batch_1')\n",
    "batch1[b'data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = unpickle('./data/cifar-10-batches-py/batches.meta')\n",
    "classes_names = meta[b'label_names']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2145b3e3390>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x50 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Ver una imagen\n",
    "img = batch1[b'data'][200].reshape(3,32,32)\n",
    "img = np.transpose(img, axes=[1, 2, 0])\n",
    "plt.rcParams[\"figure.figsize\"] = (1, 0.5)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de carpeta: 340.19 MB\n"
     ]
    }
   ],
   "source": [
    "def get_folder_size(folder_path :os.PathLike) -> str:\n",
    "    total_size = 0\n",
    "    for dirpath, _, filenames in os.walk(folder_path):\n",
    "        for filename in filenames:\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "\n",
    "            if not os.path.islink(file_path):\n",
    "                total_size += os.path.getsize(file_path)\n",
    "\n",
    "    if total_size == 0:\n",
    "        return \"0B\"\n",
    "    size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\")\n",
    "    i = int(math.floor(math.log(total_size, 1024)))\n",
    "    p = math.pow(1024, i)\n",
    "    s = round(total_size / p, 2)\n",
    "    return f\"{s} {size_name[i]}\"\n",
    "\n",
    "\n",
    "folder_path = './data'\n",
    "size_in_bytes = get_folder_size(folder_path)\n",
    "print(f\"Tamaño de carpeta: {size_in_bytes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametros del modelo: [Parameter containing:\n",
      "tensor([[[[ 0.0055,  0.0088,  0.0414, -0.1195],\n",
      "          [ 0.0932,  0.1333,  0.1113,  0.1026],\n",
      "          [-0.0300,  0.0096, -0.0473, -0.0589],\n",
      "          [-0.1089, -0.0036, -0.0945, -0.1054]],\n",
      "\n",
      "         [[ 0.0669, -0.0794, -0.0666, -0.1293],\n",
      "          [ 0.0343,  0.0708, -0.1095,  0.0793],\n",
      "          [ 0.0587, -0.1290, -0.0508, -0.0379],\n",
      "          [-0.1106,  0.0113, -0.0278,  0.0645]],\n",
      "\n",
      "         [[-0.0158, -0.0027, -0.0312, -0.0052],\n",
      "          [-0.1179,  0.0011,  0.0140, -0.0509],\n",
      "          [ 0.1380, -0.0579, -0.0635,  0.1290],\n",
      "          [-0.1091,  0.0389, -0.0067,  0.0666]]],\n",
      "\n",
      "\n",
      "        [[[-0.1069, -0.0778,  0.0110, -0.0295],\n",
      "          [-0.1054,  0.0546,  0.1066,  0.0048],\n",
      "          [ 0.1142, -0.0799, -0.1017, -0.0613],\n",
      "          [ 0.0578, -0.0814,  0.0171, -0.0423]],\n",
      "\n",
      "         [[-0.0357, -0.1298, -0.0634,  0.0710],\n",
      "          [-0.0161, -0.0242, -0.0862, -0.0458],\n",
      "          [ 0.0100, -0.1018,  0.0933, -0.0289],\n",
      "          [ 0.1015,  0.0222, -0.1319,  0.0945]],\n",
      "\n",
      "         [[ 0.0646, -0.1107,  0.0283,  0.1214],\n",
      "          [-0.0598,  0.0380, -0.0833, -0.0315],\n",
      "          [-0.0125,  0.0613, -0.0157,  0.0193],\n",
      "          [ 0.0288,  0.0740, -0.1339,  0.0954]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0139, -0.0353,  0.0547,  0.0172],\n",
      "          [-0.1198,  0.0933,  0.1171,  0.1123],\n",
      "          [-0.0212, -0.1212, -0.0854, -0.0645],\n",
      "          [-0.0957, -0.0883, -0.0975,  0.0787]],\n",
      "\n",
      "         [[-0.1028, -0.0991, -0.0673,  0.0579],\n",
      "          [-0.1103,  0.0145, -0.1314, -0.0723],\n",
      "          [ 0.1115,  0.0195,  0.0107,  0.0041],\n",
      "          [ 0.0246,  0.0596,  0.0276, -0.1142]],\n",
      "\n",
      "         [[ 0.0232, -0.0679, -0.0620, -0.0353],\n",
      "          [-0.0853, -0.0181, -0.0205, -0.0523],\n",
      "          [-0.0793,  0.0575,  0.1202, -0.1051],\n",
      "          [-0.0686, -0.0015,  0.1060,  0.0104]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0327, -0.0809,  0.0867,  0.1279],\n",
      "          [ 0.0195,  0.0285, -0.0646, -0.0821],\n",
      "          [ 0.0448, -0.0774, -0.0451, -0.0751],\n",
      "          [-0.1402, -0.0090,  0.0898,  0.0409]],\n",
      "\n",
      "         [[-0.0861, -0.0013,  0.0983,  0.0552],\n",
      "          [-0.0068, -0.0383,  0.0572, -0.0565],\n",
      "          [-0.1324,  0.0772, -0.0511,  0.1384],\n",
      "          [ 0.0471,  0.0290, -0.0583, -0.0738]],\n",
      "\n",
      "         [[ 0.0777,  0.0821, -0.0659, -0.0836],\n",
      "          [ 0.1097,  0.0050,  0.1123,  0.0718],\n",
      "          [ 0.0511,  0.0167,  0.0144, -0.1372],\n",
      "          [ 0.0702, -0.0630,  0.0389,  0.1172]]],\n",
      "\n",
      "\n",
      "        [[[-0.1278,  0.0733, -0.0543,  0.0490],\n",
      "          [ 0.1066, -0.1084,  0.0471,  0.0406],\n",
      "          [-0.0049,  0.1344, -0.1202, -0.0023],\n",
      "          [-0.0688, -0.1027, -0.0496, -0.0683]],\n",
      "\n",
      "         [[ 0.0293, -0.1055,  0.0611,  0.0424],\n",
      "          [-0.1125,  0.0004, -0.0760, -0.0314],\n",
      "          [ 0.1248,  0.1357,  0.0664, -0.0870],\n",
      "          [ 0.1030, -0.0454,  0.1203,  0.0282]],\n",
      "\n",
      "         [[-0.1085,  0.1131, -0.0325, -0.0557],\n",
      "          [-0.1340, -0.1189, -0.0980, -0.1435],\n",
      "          [ 0.1391, -0.0799, -0.0458, -0.1070],\n",
      "          [-0.0333,  0.1192, -0.0019,  0.0027]]],\n",
      "\n",
      "\n",
      "        [[[-0.0986,  0.1337,  0.1063, -0.1384],\n",
      "          [ 0.1120,  0.1430,  0.1251, -0.0567],\n",
      "          [-0.0333, -0.0211,  0.0980, -0.0203],\n",
      "          [ 0.1173,  0.0558,  0.1387, -0.0808]],\n",
      "\n",
      "         [[-0.0476,  0.0693,  0.0191, -0.1246],\n",
      "          [-0.0016,  0.0247, -0.1016, -0.0313],\n",
      "          [-0.0918,  0.1396,  0.1380,  0.1209],\n",
      "          [-0.0738,  0.0931, -0.0042,  0.1373]],\n",
      "\n",
      "         [[-0.0876,  0.1307, -0.1125,  0.1078],\n",
      "          [ 0.0548,  0.0618, -0.0503,  0.0340],\n",
      "          [-0.1196, -0.1437, -0.0834,  0.0423],\n",
      "          [ 0.0321, -0.0264,  0.0471,  0.0094]]]], device='cuda:0',\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 1.5235e-02,  3.9279e-02,  1.2818e-01, -2.7569e-02, -6.6666e-02,\n",
      "        -5.1305e-02, -5.1040e-02,  3.3071e-02, -1.0232e-01,  2.9304e-02,\n",
      "        -1.0319e-01, -1.3535e-01,  2.1855e-02, -2.1596e-02,  3.3554e-02,\n",
      "         6.6144e-02,  1.3494e-01,  2.7678e-02,  1.4048e-01, -6.2165e-02,\n",
      "         1.3985e-01, -4.9703e-02, -7.0340e-02,  2.7763e-02, -1.9635e-02,\n",
      "         8.7411e-02, -4.9056e-02,  2.7036e-02, -4.2138e-02, -9.6543e-03,\n",
      "         3.4764e-02, -1.1143e-01,  1.1705e-01, -5.4150e-02, -8.1367e-02,\n",
      "        -5.4350e-02,  4.2384e-02, -1.1275e-02,  7.6432e-02, -8.1782e-02,\n",
      "        -6.5492e-02, -8.2678e-02, -3.0945e-02, -6.6733e-03,  1.9272e-02,\n",
      "        -3.7502e-02,  9.3083e-02, -6.9179e-02, -5.9727e-02, -1.4191e-01,\n",
      "        -1.2859e-01,  1.3324e-01, -3.7632e-02,  4.9874e-02,  2.8018e-03,\n",
      "         1.5613e-02, -7.9714e-02,  3.9734e-02,  1.1825e-01, -6.6799e-02,\n",
      "         5.9204e-02, -1.2308e-01,  4.9437e-02,  1.1046e-01,  5.2087e-02,\n",
      "        -2.9957e-02,  8.1063e-02, -9.0625e-02,  6.3409e-02,  1.4160e-03,\n",
      "        -7.0089e-02, -1.4368e-01,  1.3404e-01, -6.1945e-02,  2.4979e-03,\n",
      "        -8.6931e-02, -1.1503e-01, -3.5990e-02, -9.2322e-02, -1.4350e-02,\n",
      "         8.5445e-02,  1.4020e-01,  1.1866e-01,  5.2846e-02, -1.2566e-01,\n",
      "         8.8751e-02,  8.5234e-02, -8.6716e-03,  4.5153e-02, -1.1935e-01,\n",
      "        -4.8479e-03, -1.3967e-01, -2.7441e-02,  5.4900e-02,  7.6978e-02,\n",
      "         6.7456e-02, -8.6031e-02, -1.7650e-03,  8.4843e-02, -4.3979e-02,\n",
      "        -1.1797e-01, -1.8949e-02,  1.4296e-01, -3.6010e-02,  1.1847e-01,\n",
      "        -8.0965e-03, -9.3030e-02,  7.8954e-03, -1.3864e-01, -1.3065e-01,\n",
      "         4.9641e-03, -2.4836e-02, -8.1329e-02,  1.3663e-01, -7.4730e-02,\n",
      "         1.9121e-02, -4.4550e-02, -7.0802e-02,  5.2218e-02, -4.7051e-02,\n",
      "         1.8419e-02, -4.1085e-02, -6.6730e-02,  9.9572e-02,  1.0323e-01,\n",
      "        -7.6785e-02,  7.7876e-02, -8.3381e-02, -1.3794e-01, -8.7368e-02,\n",
      "         6.0075e-03,  3.7803e-02, -1.8910e-02,  1.3515e-02,  2.8001e-02,\n",
      "        -3.9466e-02,  6.0095e-03,  9.2692e-02,  1.0527e-01,  1.1351e-01,\n",
      "         1.0882e-01,  3.7649e-02,  1.2429e-01, -5.5339e-02,  7.2214e-02,\n",
      "         8.9309e-02,  6.4565e-02, -8.8824e-02,  5.8524e-02,  9.1794e-04,\n",
      "        -9.1749e-02, -1.1851e-01,  9.5616e-02, -1.3760e-01,  2.5576e-02,\n",
      "         7.2820e-02,  1.1251e-01, -1.1224e-01, -1.0739e-02,  1.1246e-01,\n",
      "        -1.1818e-01,  9.0800e-03,  4.8647e-02,  6.6386e-02, -7.5170e-02,\n",
      "        -1.1111e-01, -6.4482e-02, -9.8923e-02,  1.1741e-01, -8.6482e-02,\n",
      "         6.3197e-02, -1.0390e-01, -1.2279e-01, -1.1286e-01, -1.3793e-01,\n",
      "        -9.1679e-02,  6.3673e-02,  8.2891e-02,  1.4355e-01,  8.5744e-02,\n",
      "        -9.2946e-02,  4.4706e-02,  1.6243e-02,  3.3706e-02, -1.0162e-01,\n",
      "         8.3779e-02, -1.3753e-01,  9.2643e-02,  1.9093e-02,  5.6613e-02,\n",
      "         1.0548e-01, -1.2051e-01, -1.3616e-01, -6.3899e-02, -5.1218e-02,\n",
      "         1.1506e-01,  4.5027e-02, -7.6830e-02, -4.7361e-02, -4.4468e-02,\n",
      "        -1.1519e-01, -1.1567e-02,  1.1599e-01,  4.9516e-02, -1.3785e-02,\n",
      "        -1.2582e-02,  1.1184e-01,  1.4237e-01, -9.9018e-02,  4.8526e-02,\n",
      "        -5.8463e-02,  1.4947e-02,  5.6593e-02, -1.1635e-02,  1.0475e-01,\n",
      "         1.1235e-02,  1.3029e-01,  6.8454e-02,  1.3560e-01, -9.9171e-02,\n",
      "         4.0069e-03,  1.3201e-01,  3.3195e-02,  3.4410e-02,  9.5078e-03,\n",
      "        -1.3598e-01, -6.8943e-02,  1.0495e-01, -2.8411e-04,  9.3021e-02,\n",
      "         6.6044e-02, -7.5442e-02,  6.3515e-02, -1.2042e-01,  2.2350e-02,\n",
      "         1.3436e-02,  1.3528e-02, -1.1359e-01,  8.7057e-02, -2.6784e-02,\n",
      "         1.2974e-01,  9.3779e-02, -3.7951e-03, -1.2916e-02,  8.7768e-02,\n",
      "         1.2185e-01,  7.8658e-02, -8.9421e-02, -1.2124e-01,  2.3540e-02,\n",
      "         7.6699e-02,  6.8999e-02,  3.9786e-02,  8.9094e-02,  7.2362e-02,\n",
      "        -1.1501e-01, -1.2744e-01,  9.4241e-02, -1.0660e-01,  4.4942e-02,\n",
      "         1.1286e-01, -3.3622e-02,  5.8620e-02,  7.6900e-02,  1.1298e-01,\n",
      "        -1.2940e-01,  5.5353e-02, -1.3971e-01,  1.1720e-01,  9.0377e-02,\n",
      "        -5.5264e-03,  1.3303e-01,  4.9555e-02,  1.0461e-01,  1.1944e-01,\n",
      "         8.4187e-03,  4.8526e-02,  1.0818e-02, -2.8172e-02, -4.0504e-03,\n",
      "         1.2948e-01,  2.9434e-02, -3.6967e-02,  1.3417e-01,  1.3771e-01,\n",
      "        -9.2626e-02,  2.3349e-02, -5.8122e-02, -1.2887e-01, -1.3881e-01,\n",
      "        -8.5007e-02, -3.6926e-03,  2.0897e-02, -5.1571e-02,  1.3828e-01,\n",
      "        -8.3507e-02, -9.9018e-02, -8.9996e-02,  8.3444e-02,  9.1281e-02,\n",
      "         6.2606e-02, -1.2982e-01, -7.9969e-02, -5.2420e-02,  1.0414e-02,\n",
      "         9.5109e-02,  8.1749e-02,  1.0887e-02,  4.7552e-02,  1.2662e-01,\n",
      "        -7.1036e-02,  3.1429e-02,  4.6082e-02,  6.8202e-02, -5.7189e-02,\n",
      "         1.2515e-01, -7.2670e-02, -1.3029e-01,  5.9058e-02,  8.5154e-02,\n",
      "         5.0154e-02,  4.9545e-02, -1.3372e-01,  3.1585e-02, -1.0373e-01,\n",
      "        -1.0928e-01,  8.7389e-02, -1.0434e-01,  8.5094e-02, -9.4261e-02,\n",
      "         2.9470e-02,  6.9410e-02, -5.2302e-02,  1.2557e-02,  5.3186e-03,\n",
      "        -2.4650e-02, -4.5708e-02, -2.5329e-02, -1.1460e-01,  1.3697e-01,\n",
      "        -6.3631e-02, -1.3911e-01, -1.7263e-02,  1.4086e-01, -6.8443e-02,\n",
      "         6.8843e-02,  1.3494e-01, -1.2966e-01, -9.0583e-02, -4.0470e-02,\n",
      "        -7.1263e-03, -5.5615e-02,  3.7138e-02, -2.3274e-02,  5.5870e-02,\n",
      "        -1.3094e-01, -1.3427e-01, -8.3040e-02, -5.5474e-03,  1.7718e-02,\n",
      "         1.1716e-01, -5.8140e-02, -6.7029e-02,  8.3766e-02,  1.0006e-01,\n",
      "        -2.5895e-02, -7.7180e-02,  8.7439e-02,  1.1296e-01, -2.7503e-02,\n",
      "        -1.0476e-01, -1.3989e-01,  1.8867e-03, -5.9320e-02, -1.1317e-01,\n",
      "         9.3559e-02,  3.9676e-02,  8.4497e-02, -1.0995e-01,  1.0310e-01,\n",
      "        -1.0456e-01, -1.4277e-01,  4.2388e-02, -4.3112e-02, -1.0396e-02,\n",
      "         1.3851e-01, -1.2076e-01, -9.6503e-02, -1.3358e-01, -4.8421e-02,\n",
      "        -1.2684e-01, -1.0158e-04,  6.6366e-02, -1.4120e-01, -1.4362e-01,\n",
      "        -9.5528e-03,  6.9575e-03, -4.9947e-02, -5.0215e-02,  6.5689e-02,\n",
      "        -9.9046e-02, -8.0097e-02,  8.3997e-02,  6.3573e-02, -4.6903e-02,\n",
      "        -3.6496e-02,  1.1166e-02,  1.4282e-01, -1.4016e-01, -4.8332e-02,\n",
      "         7.5949e-02,  1.0443e-01,  3.6356e-02, -3.6903e-02, -1.0490e-02,\n",
      "        -5.2684e-02, -4.1509e-02,  5.9116e-02, -8.9866e-03, -4.5300e-02,\n",
      "        -4.8657e-02, -1.3322e-01, -9.5116e-02, -1.1336e-01, -2.8886e-02,\n",
      "         1.0562e-01, -3.8408e-02,  9.3094e-02, -3.7954e-02, -5.4236e-03,\n",
      "        -1.2417e-01,  1.8825e-02, -1.5645e-02, -7.1890e-02, -1.1731e-01,\n",
      "         9.3070e-02,  4.5474e-02, -1.1640e-01, -1.1468e-01, -8.6923e-03,\n",
      "        -7.5843e-02, -1.3285e-01,  6.6691e-02,  2.6775e-02,  2.5287e-02,\n",
      "         5.9954e-02, -2.4380e-02, -3.2650e-03, -1.4038e-01, -2.6614e-02,\n",
      "         5.6538e-02,  5.8316e-02, -1.0467e-01, -1.0549e-02,  1.1859e-02,\n",
      "        -9.9609e-02,  1.2233e-01,  1.0619e-01,  7.6574e-02, -1.3588e-01,\n",
      "         1.2902e-01, -1.2689e-01, -8.0491e-03, -1.1492e-02,  6.2093e-02,\n",
      "        -1.2302e-01, -3.9380e-02, -1.1482e-01,  1.0467e-01,  9.3925e-02,\n",
      "        -3.8621e-03, -4.3760e-02, -1.9498e-02,  7.1918e-02, -7.7993e-02,\n",
      "         7.6086e-02,  6.5570e-02,  9.5381e-02,  7.5371e-02,  3.7727e-02,\n",
      "        -1.2070e-01,  5.9814e-02,  7.5234e-02, -1.0540e-01, -9.7066e-02,\n",
      "        -7.0592e-02,  2.7531e-02, -4.0758e-02, -1.5453e-02, -2.2755e-02,\n",
      "        -2.2169e-02, -7.6842e-02, -3.9441e-02, -6.0158e-02, -1.3130e-02,\n",
      "        -1.1351e-01, -1.4346e-01, -1.0199e-01, -8.7746e-02,  8.5602e-02,\n",
      "        -5.1892e-03,  1.6633e-02, -2.0635e-02, -1.7857e-02,  1.2880e-01,\n",
      "         9.4814e-03,  1.8521e-02, -6.1801e-02, -1.1865e-01, -1.0481e-01,\n",
      "        -1.1997e-02, -3.3196e-03,  2.1331e-02,  6.5805e-03, -5.5589e-02,\n",
      "         1.4130e-01,  2.0925e-02, -8.5268e-02, -1.0166e-01, -8.6014e-02,\n",
      "         7.2533e-02, -1.3510e-03,  1.3646e-02,  1.0473e-01, -1.3113e-01,\n",
      "         1.0908e-02, -1.2507e-01,  7.1549e-02,  1.3828e-01,  1.1553e-02,\n",
      "         7.4525e-02,  9.4187e-02, -2.3074e-02, -7.6761e-02,  9.8818e-02,\n",
      "        -1.2457e-02, -1.2901e-01,  2.4185e-02,  4.8434e-02,  1.2405e-01,\n",
      "        -1.9949e-03, -5.5383e-02, -5.6883e-02,  3.5720e-02, -8.9406e-02,\n",
      "         8.6716e-02,  2.2619e-02,  8.3876e-02,  4.7537e-02,  1.4092e-01,\n",
      "        -2.3805e-02, -7.1582e-02,  1.0413e-01,  1.2826e-01, -1.0575e-01,\n",
      "        -3.9600e-02,  1.9359e-02,  1.1593e-01,  4.3000e-02,  1.8967e-03,\n",
      "         2.1190e-02, -2.3396e-03,  4.5922e-02,  5.0313e-02,  9.5457e-02,\n",
      "         1.0570e-02,  6.1993e-02,  1.2846e-01,  4.1319e-02, -7.4895e-02,\n",
      "         1.0006e-01, -4.9585e-02,  2.8887e-02, -8.1490e-02,  4.1269e-02,\n",
      "        -9.5565e-02,  4.0827e-03, -8.2710e-02, -1.3595e-01,  5.3091e-02,\n",
      "         1.4033e-01, -1.2257e-01,  1.3375e-01,  4.4892e-02, -6.1374e-02,\n",
      "         8.7393e-02,  6.7815e-02,  7.2124e-03, -8.9691e-03, -1.4116e-01,\n",
      "        -1.2896e-01, -5.2398e-02,  4.7931e-02, -1.4022e-01, -9.8678e-02,\n",
      "         5.0253e-02, -1.2141e-01, -9.3060e-03,  5.7263e-02,  1.1542e-01,\n",
      "        -8.6886e-03,  1.3726e-01, -5.8677e-02,  2.6839e-02, -1.0444e-01,\n",
      "        -1.0888e-01, -6.4652e-02, -9.9862e-02, -1.1346e-01, -4.8876e-02,\n",
      "        -8.5869e-02, -6.6466e-02, -7.7597e-02, -3.5285e-02, -3.8108e-02,\n",
      "        -7.4235e-02,  1.0780e-01,  1.0312e-01,  1.1627e-01,  3.6678e-02,\n",
      "        -1.1610e-02, -3.9355e-02, -1.3514e-01,  1.8056e-02,  8.0268e-02,\n",
      "        -8.5346e-02, -3.8130e-03,  8.7590e-02, -1.1926e-02, -1.3844e-01,\n",
      "         6.4887e-02,  1.1609e-01,  3.4814e-02,  2.1431e-02,  8.1042e-02,\n",
      "        -8.6302e-02, -3.4022e-02, -3.0300e-02,  6.2750e-02, -1.3511e-01,\n",
      "         1.5199e-02,  4.5365e-02, -8.2772e-02, -6.8585e-02,  1.0723e-01,\n",
      "        -1.3359e-01,  7.4120e-02,  4.7293e-02,  1.4344e-01,  3.7177e-03,\n",
      "        -1.0760e-01, -1.3219e-01,  1.1044e-01, -8.0179e-02, -1.4324e-01,\n",
      "        -4.0458e-02,  1.4678e-02,  7.9817e-02,  5.5092e-02, -2.0193e-02,\n",
      "         7.5831e-02,  1.1239e-01,  7.4020e-02, -3.4955e-02, -1.2543e-01,\n",
      "         6.3119e-02, -1.2601e-01,  1.8349e-02, -4.5572e-02, -6.1362e-02,\n",
      "        -7.4315e-02, -1.3974e-01,  5.7271e-02, -3.2857e-02, -1.1364e-01,\n",
      "         5.9488e-02, -7.4641e-02, -2.6471e-02, -9.4616e-02,  1.3267e-01,\n",
      "        -1.2215e-01,  6.8011e-02, -4.0978e-02, -1.0379e-01, -3.2699e-02,\n",
      "        -9.1130e-02,  1.8347e-02,  4.9276e-02,  9.8128e-02,  6.0969e-02,\n",
      "        -9.2371e-02, -8.5474e-02, -7.8200e-02, -7.3978e-02,  3.3801e-02,\n",
      "        -5.1088e-03,  1.0679e-02, -9.7428e-03,  2.7481e-02, -3.1126e-02,\n",
      "        -8.2494e-02,  9.4711e-02, -2.4712e-02, -7.6854e-02,  3.9394e-02,\n",
      "         1.0390e-01,  6.9118e-02, -2.8557e-02,  7.8693e-02, -2.7130e-02,\n",
      "         5.4361e-02,  3.7698e-02, -8.9798e-02,  8.4513e-02,  1.4261e-01,\n",
      "        -7.8387e-02, -5.4766e-02,  1.4299e-01, -3.6089e-03, -1.1854e-01,\n",
      "         2.0209e-02,  1.1011e-01, -5.5584e-02,  6.6551e-02,  7.1001e-02,\n",
      "        -2.2614e-02,  3.9172e-02, -6.4945e-02, -2.0639e-02, -1.3551e-01,\n",
      "        -8.0877e-02, -2.7485e-02, -7.9525e-02, -1.3451e-01, -7.1893e-02,\n",
      "        -9.1057e-03,  1.2030e-01, -1.0940e-02,  4.6378e-02, -1.1147e-01,\n",
      "         7.0577e-02,  6.6189e-02,  1.1439e-03,  4.1002e-02,  7.1795e-02,\n",
      "        -6.2622e-02,  9.1891e-02, -6.8301e-03, -2.2796e-02,  9.7567e-02,\n",
      "        -8.6671e-02, -1.0666e-01, -1.1900e-01, -1.3497e-01, -9.0607e-02,\n",
      "         4.8890e-02, -1.1708e-01, -7.7643e-02,  1.4077e-01, -4.4921e-02,\n",
      "        -1.1478e-01,  7.4511e-02,  1.3694e-01, -7.0022e-02,  1.0316e-01,\n",
      "        -1.2017e-01, -7.8479e-02, -4.8095e-02], device='cuda:0',\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0327,  0.0363,  0.0217,  ...,  0.0205, -0.0111,  0.0185],\n",
      "        [-0.0006, -0.0264, -0.0192,  ...,  0.0126,  0.0275, -0.0388],\n",
      "        [-0.0192, -0.0244,  0.0241,  ...,  0.0043,  0.0346, -0.0081],\n",
      "        ...,\n",
      "        [ 0.0079, -0.0235,  0.0048,  ..., -0.0130,  0.0337,  0.0199],\n",
      "        [-0.0202, -0.0078,  0.0192,  ..., -0.0410, -0.0019, -0.0295],\n",
      "        [ 0.0433, -0.0215,  0.0156,  ...,  0.0027,  0.0433, -0.0127]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0270,  0.0048,  0.0301,  ..., -0.0066,  0.0180,  0.0165],\n",
      "        [-0.0059, -0.0329,  0.0221,  ..., -0.0089, -0.0254, -0.0311],\n",
      "        [-0.0307,  0.0085,  0.0304,  ..., -0.0226,  0.0146,  0.0323],\n",
      "        ...,\n",
      "        [ 0.0188,  0.0203, -0.0349,  ..., -0.0200, -0.0006, -0.0303],\n",
      "        [-0.0347, -0.0097,  0.0267,  ..., -0.0353,  0.0239, -0.0089],\n",
      "        [ 0.0258, -0.0341,  0.0252,  ..., -0.0228,  0.0192, -0.0285]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[-3.2999e-02, -1.3734e-02, -1.9887e-02,  ..., -1.6215e-02,\n",
      "          3.3592e-02,  9.8895e-05],\n",
      "        [-2.9419e-02, -1.3544e-03,  1.1349e-02,  ...,  1.3619e-03,\n",
      "         -1.6268e-02, -2.1768e-02],\n",
      "        [-5.7686e-03,  3.0205e-02, -2.5170e-02,  ...,  1.7692e-02,\n",
      "          3.5745e-02, -1.0627e-02],\n",
      "        ...,\n",
      "        [ 2.7148e-02,  1.2641e-03,  2.2656e-02,  ...,  6.6692e-03,\n",
      "          6.5282e-03,  3.2948e-02],\n",
      "        [-1.3908e-02, -2.3762e-02, -7.2006e-03,  ..., -1.3328e-02,\n",
      "         -1.8754e-02, -1.7524e-02],\n",
      "        [ 2.6974e-02,  2.6386e-02, -3.8000e-03,  ..., -7.3520e-03,\n",
      "          2.2222e-02,  1.4074e-02]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0218, -0.0021, -0.0193,  ..., -0.0016,  0.0020, -0.0074],\n",
      "        [-0.0244,  0.0268,  0.0041,  ..., -0.0180, -0.0186,  0.0180],\n",
      "        [ 0.0274,  0.0007,  0.0123,  ...,  0.0209, -0.0091, -0.0097],\n",
      "        ...,\n",
      "        [ 0.0142, -0.0174,  0.0006,  ...,  0.0097, -0.0163,  0.0180],\n",
      "        [ 0.0228, -0.0164, -0.0266,  ...,  0.0041, -0.0016,  0.0154],\n",
      "        [-0.0027, -0.0005, -0.0219,  ...,  0.0036,  0.0023,  0.0040]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0327,  0.0363,  0.0217,  ...,  0.0205, -0.0111,  0.0185],\n",
      "        [-0.0006, -0.0264, -0.0192,  ...,  0.0126,  0.0275, -0.0388],\n",
      "        [-0.0192, -0.0244,  0.0241,  ...,  0.0043,  0.0346, -0.0081],\n",
      "        ...,\n",
      "        [ 0.0079, -0.0235,  0.0048,  ..., -0.0130,  0.0337,  0.0199],\n",
      "        [-0.0202, -0.0078,  0.0192,  ..., -0.0410, -0.0019, -0.0295],\n",
      "        [ 0.0433, -0.0215,  0.0156,  ...,  0.0027,  0.0433, -0.0127]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0270,  0.0048,  0.0301,  ..., -0.0066,  0.0180,  0.0165],\n",
      "        [-0.0059, -0.0329,  0.0221,  ..., -0.0089, -0.0254, -0.0311],\n",
      "        [-0.0307,  0.0085,  0.0304,  ..., -0.0226,  0.0146,  0.0323],\n",
      "        ...,\n",
      "        [ 0.0188,  0.0203, -0.0349,  ..., -0.0200, -0.0006, -0.0303],\n",
      "        [-0.0347, -0.0097,  0.0267,  ..., -0.0353,  0.0239, -0.0089],\n",
      "        [ 0.0258, -0.0341,  0.0252,  ..., -0.0228,  0.0192, -0.0285]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[-3.2999e-02, -1.3734e-02, -1.9887e-02,  ..., -1.6215e-02,\n",
      "          3.3592e-02,  9.8895e-05],\n",
      "        [-2.9419e-02, -1.3544e-03,  1.1349e-02,  ...,  1.3619e-03,\n",
      "         -1.6268e-02, -2.1768e-02],\n",
      "        [-5.7686e-03,  3.0205e-02, -2.5170e-02,  ...,  1.7692e-02,\n",
      "          3.5745e-02, -1.0627e-02],\n",
      "        ...,\n",
      "        [ 2.7148e-02,  1.2641e-03,  2.2656e-02,  ...,  6.6692e-03,\n",
      "          6.5282e-03,  3.2948e-02],\n",
      "        [-1.3908e-02, -2.3762e-02, -7.2006e-03,  ..., -1.3328e-02,\n",
      "         -1.8754e-02, -1.7524e-02],\n",
      "        [ 2.6974e-02,  2.6386e-02, -3.8000e-03,  ..., -7.3520e-03,\n",
      "          2.2222e-02,  1.4074e-02]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0218, -0.0021, -0.0193,  ..., -0.0016,  0.0020, -0.0074],\n",
      "        [-0.0244,  0.0268,  0.0041,  ..., -0.0180, -0.0186,  0.0180],\n",
      "        [ 0.0274,  0.0007,  0.0123,  ...,  0.0209, -0.0091, -0.0097],\n",
      "        ...,\n",
      "        [ 0.0142, -0.0174,  0.0006,  ...,  0.0097, -0.0163,  0.0180],\n",
      "        [ 0.0228, -0.0164, -0.0266,  ...,  0.0041, -0.0016,  0.0154],\n",
      "        [-0.0027, -0.0005, -0.0219,  ...,  0.0036,  0.0023,  0.0040]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0327,  0.0363,  0.0217,  ...,  0.0205, -0.0111,  0.0185],\n",
      "        [-0.0006, -0.0264, -0.0192,  ...,  0.0126,  0.0275, -0.0388],\n",
      "        [-0.0192, -0.0244,  0.0241,  ...,  0.0043,  0.0346, -0.0081],\n",
      "        ...,\n",
      "        [ 0.0079, -0.0235,  0.0048,  ..., -0.0130,  0.0337,  0.0199],\n",
      "        [-0.0202, -0.0078,  0.0192,  ..., -0.0410, -0.0019, -0.0295],\n",
      "        [ 0.0433, -0.0215,  0.0156,  ...,  0.0027,  0.0433, -0.0127]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0270,  0.0048,  0.0301,  ..., -0.0066,  0.0180,  0.0165],\n",
      "        [-0.0059, -0.0329,  0.0221,  ..., -0.0089, -0.0254, -0.0311],\n",
      "        [-0.0307,  0.0085,  0.0304,  ..., -0.0226,  0.0146,  0.0323],\n",
      "        ...,\n",
      "        [ 0.0188,  0.0203, -0.0349,  ..., -0.0200, -0.0006, -0.0303],\n",
      "        [-0.0347, -0.0097,  0.0267,  ..., -0.0353,  0.0239, -0.0089],\n",
      "        [ 0.0258, -0.0341,  0.0252,  ..., -0.0228,  0.0192, -0.0285]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[-3.2999e-02, -1.3734e-02, -1.9887e-02,  ..., -1.6215e-02,\n",
      "          3.3592e-02,  9.8895e-05],\n",
      "        [-2.9419e-02, -1.3544e-03,  1.1349e-02,  ...,  1.3619e-03,\n",
      "         -1.6268e-02, -2.1768e-02],\n",
      "        [-5.7686e-03,  3.0205e-02, -2.5170e-02,  ...,  1.7692e-02,\n",
      "          3.5745e-02, -1.0627e-02],\n",
      "        ...,\n",
      "        [ 2.7148e-02,  1.2641e-03,  2.2656e-02,  ...,  6.6692e-03,\n",
      "          6.5282e-03,  3.2948e-02],\n",
      "        [-1.3908e-02, -2.3762e-02, -7.2006e-03,  ..., -1.3328e-02,\n",
      "         -1.8754e-02, -1.7524e-02],\n",
      "        [ 2.6974e-02,  2.6386e-02, -3.8000e-03,  ..., -7.3520e-03,\n",
      "          2.2222e-02,  1.4074e-02]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0218, -0.0021, -0.0193,  ..., -0.0016,  0.0020, -0.0074],\n",
      "        [-0.0244,  0.0268,  0.0041,  ..., -0.0180, -0.0186,  0.0180],\n",
      "        [ 0.0274,  0.0007,  0.0123,  ...,  0.0209, -0.0091, -0.0097],\n",
      "        ...,\n",
      "        [ 0.0142, -0.0174,  0.0006,  ...,  0.0097, -0.0163,  0.0180],\n",
      "        [ 0.0228, -0.0164, -0.0266,  ...,  0.0041, -0.0016,  0.0154],\n",
      "        [-0.0027, -0.0005, -0.0219,  ...,  0.0036,  0.0023,  0.0040]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0327,  0.0363,  0.0217,  ...,  0.0205, -0.0111,  0.0185],\n",
      "        [-0.0006, -0.0264, -0.0192,  ...,  0.0126,  0.0275, -0.0388],\n",
      "        [-0.0192, -0.0244,  0.0241,  ...,  0.0043,  0.0346, -0.0081],\n",
      "        ...,\n",
      "        [ 0.0079, -0.0235,  0.0048,  ..., -0.0130,  0.0337,  0.0199],\n",
      "        [-0.0202, -0.0078,  0.0192,  ..., -0.0410, -0.0019, -0.0295],\n",
      "        [ 0.0433, -0.0215,  0.0156,  ...,  0.0027,  0.0433, -0.0127]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0270,  0.0048,  0.0301,  ..., -0.0066,  0.0180,  0.0165],\n",
      "        [-0.0059, -0.0329,  0.0221,  ..., -0.0089, -0.0254, -0.0311],\n",
      "        [-0.0307,  0.0085,  0.0304,  ..., -0.0226,  0.0146,  0.0323],\n",
      "        ...,\n",
      "        [ 0.0188,  0.0203, -0.0349,  ..., -0.0200, -0.0006, -0.0303],\n",
      "        [-0.0347, -0.0097,  0.0267,  ..., -0.0353,  0.0239, -0.0089],\n",
      "        [ 0.0258, -0.0341,  0.0252,  ..., -0.0228,  0.0192, -0.0285]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[-3.2999e-02, -1.3734e-02, -1.9887e-02,  ..., -1.6215e-02,\n",
      "          3.3592e-02,  9.8895e-05],\n",
      "        [-2.9419e-02, -1.3544e-03,  1.1349e-02,  ...,  1.3619e-03,\n",
      "         -1.6268e-02, -2.1768e-02],\n",
      "        [-5.7686e-03,  3.0205e-02, -2.5170e-02,  ...,  1.7692e-02,\n",
      "          3.5745e-02, -1.0627e-02],\n",
      "        ...,\n",
      "        [ 2.7148e-02,  1.2641e-03,  2.2656e-02,  ...,  6.6692e-03,\n",
      "          6.5282e-03,  3.2948e-02],\n",
      "        [-1.3908e-02, -2.3762e-02, -7.2006e-03,  ..., -1.3328e-02,\n",
      "         -1.8754e-02, -1.7524e-02],\n",
      "        [ 2.6974e-02,  2.6386e-02, -3.8000e-03,  ..., -7.3520e-03,\n",
      "          2.2222e-02,  1.4074e-02]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0218, -0.0021, -0.0193,  ..., -0.0016,  0.0020, -0.0074],\n",
      "        [-0.0244,  0.0268,  0.0041,  ..., -0.0180, -0.0186,  0.0180],\n",
      "        [ 0.0274,  0.0007,  0.0123,  ...,  0.0209, -0.0091, -0.0097],\n",
      "        ...,\n",
      "        [ 0.0142, -0.0174,  0.0006,  ...,  0.0097, -0.0163,  0.0180],\n",
      "        [ 0.0228, -0.0164, -0.0266,  ...,  0.0041, -0.0016,  0.0154],\n",
      "        [-0.0027, -0.0005, -0.0219,  ...,  0.0036,  0.0023,  0.0040]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0327,  0.0363,  0.0217,  ...,  0.0205, -0.0111,  0.0185],\n",
      "        [-0.0006, -0.0264, -0.0192,  ...,  0.0126,  0.0275, -0.0388],\n",
      "        [-0.0192, -0.0244,  0.0241,  ...,  0.0043,  0.0346, -0.0081],\n",
      "        ...,\n",
      "        [ 0.0079, -0.0235,  0.0048,  ..., -0.0130,  0.0337,  0.0199],\n",
      "        [-0.0202, -0.0078,  0.0192,  ..., -0.0410, -0.0019, -0.0295],\n",
      "        [ 0.0433, -0.0215,  0.0156,  ...,  0.0027,  0.0433, -0.0127]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0270,  0.0048,  0.0301,  ..., -0.0066,  0.0180,  0.0165],\n",
      "        [-0.0059, -0.0329,  0.0221,  ..., -0.0089, -0.0254, -0.0311],\n",
      "        [-0.0307,  0.0085,  0.0304,  ..., -0.0226,  0.0146,  0.0323],\n",
      "        ...,\n",
      "        [ 0.0188,  0.0203, -0.0349,  ..., -0.0200, -0.0006, -0.0303],\n",
      "        [-0.0347, -0.0097,  0.0267,  ..., -0.0353,  0.0239, -0.0089],\n",
      "        [ 0.0258, -0.0341,  0.0252,  ..., -0.0228,  0.0192, -0.0285]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[-3.2999e-02, -1.3734e-02, -1.9887e-02,  ..., -1.6215e-02,\n",
      "          3.3592e-02,  9.8895e-05],\n",
      "        [-2.9419e-02, -1.3544e-03,  1.1349e-02,  ...,  1.3619e-03,\n",
      "         -1.6268e-02, -2.1768e-02],\n",
      "        [-5.7686e-03,  3.0205e-02, -2.5170e-02,  ...,  1.7692e-02,\n",
      "          3.5745e-02, -1.0627e-02],\n",
      "        ...,\n",
      "        [ 2.7148e-02,  1.2641e-03,  2.2656e-02,  ...,  6.6692e-03,\n",
      "          6.5282e-03,  3.2948e-02],\n",
      "        [-1.3908e-02, -2.3762e-02, -7.2006e-03,  ..., -1.3328e-02,\n",
      "         -1.8754e-02, -1.7524e-02],\n",
      "        [ 2.6974e-02,  2.6386e-02, -3.8000e-03,  ..., -7.3520e-03,\n",
      "          2.2222e-02,  1.4074e-02]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0218, -0.0021, -0.0193,  ..., -0.0016,  0.0020, -0.0074],\n",
      "        [-0.0244,  0.0268,  0.0041,  ..., -0.0180, -0.0186,  0.0180],\n",
      "        [ 0.0274,  0.0007,  0.0123,  ...,  0.0209, -0.0091, -0.0097],\n",
      "        ...,\n",
      "        [ 0.0142, -0.0174,  0.0006,  ...,  0.0097, -0.0163,  0.0180],\n",
      "        [ 0.0228, -0.0164, -0.0266,  ...,  0.0041, -0.0016,  0.0154],\n",
      "        [-0.0027, -0.0005, -0.0219,  ...,  0.0036,  0.0023,  0.0040]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0327,  0.0363,  0.0217,  ...,  0.0205, -0.0111,  0.0185],\n",
      "        [-0.0006, -0.0264, -0.0192,  ...,  0.0126,  0.0275, -0.0388],\n",
      "        [-0.0192, -0.0244,  0.0241,  ...,  0.0043,  0.0346, -0.0081],\n",
      "        ...,\n",
      "        [ 0.0079, -0.0235,  0.0048,  ..., -0.0130,  0.0337,  0.0199],\n",
      "        [-0.0202, -0.0078,  0.0192,  ..., -0.0410, -0.0019, -0.0295],\n",
      "        [ 0.0433, -0.0215,  0.0156,  ...,  0.0027,  0.0433, -0.0127]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0270,  0.0048,  0.0301,  ..., -0.0066,  0.0180,  0.0165],\n",
      "        [-0.0059, -0.0329,  0.0221,  ..., -0.0089, -0.0254, -0.0311],\n",
      "        [-0.0307,  0.0085,  0.0304,  ..., -0.0226,  0.0146,  0.0323],\n",
      "        ...,\n",
      "        [ 0.0188,  0.0203, -0.0349,  ..., -0.0200, -0.0006, -0.0303],\n",
      "        [-0.0347, -0.0097,  0.0267,  ..., -0.0353,  0.0239, -0.0089],\n",
      "        [ 0.0258, -0.0341,  0.0252,  ..., -0.0228,  0.0192, -0.0285]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[-3.2999e-02, -1.3734e-02, -1.9887e-02,  ..., -1.6215e-02,\n",
      "          3.3592e-02,  9.8895e-05],\n",
      "        [-2.9419e-02, -1.3544e-03,  1.1349e-02,  ...,  1.3619e-03,\n",
      "         -1.6268e-02, -2.1768e-02],\n",
      "        [-5.7686e-03,  3.0205e-02, -2.5170e-02,  ...,  1.7692e-02,\n",
      "          3.5745e-02, -1.0627e-02],\n",
      "        ...,\n",
      "        [ 2.7148e-02,  1.2641e-03,  2.2656e-02,  ...,  6.6692e-03,\n",
      "          6.5282e-03,  3.2948e-02],\n",
      "        [-1.3908e-02, -2.3762e-02, -7.2006e-03,  ..., -1.3328e-02,\n",
      "         -1.8754e-02, -1.7524e-02],\n",
      "        [ 2.6974e-02,  2.6386e-02, -3.8000e-03,  ..., -7.3520e-03,\n",
      "          2.2222e-02,  1.4074e-02]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0218, -0.0021, -0.0193,  ..., -0.0016,  0.0020, -0.0074],\n",
      "        [-0.0244,  0.0268,  0.0041,  ..., -0.0180, -0.0186,  0.0180],\n",
      "        [ 0.0274,  0.0007,  0.0123,  ...,  0.0209, -0.0091, -0.0097],\n",
      "        ...,\n",
      "        [ 0.0142, -0.0174,  0.0006,  ...,  0.0097, -0.0163,  0.0180],\n",
      "        [ 0.0228, -0.0164, -0.0266,  ...,  0.0041, -0.0016,  0.0154],\n",
      "        [-0.0027, -0.0005, -0.0219,  ...,  0.0036,  0.0023,  0.0040]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034, -0.0009,  ...,  0.0004,  0.0022, -0.0010],\n",
      "        [ 0.0008,  0.0021, -0.0027,  ...,  0.0004,  0.0037,  0.0012],\n",
      "        [-0.0019, -0.0001,  0.0040,  ...,  0.0042, -0.0033, -0.0024],\n",
      "        ...,\n",
      "        [ 0.0023, -0.0009,  0.0031,  ...,  0.0018, -0.0002,  0.0023],\n",
      "        [ 0.0006,  0.0020, -0.0001,  ...,  0.0037, -0.0031, -0.0004],\n",
      "        [ 0.0019,  0.0002, -0.0013,  ...,  0.0042,  0.0039, -0.0044]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([-0.0021, -0.0024, -0.0026,  ..., -0.0015,  0.0009, -0.0006],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 4.7622e-03,  1.6679e-02, -4.2976e-03,  ...,  6.0439e-03,\n",
      "         -1.5453e-02,  2.3641e-02],\n",
      "        [-3.6198e-03, -1.5480e-02,  1.4504e-03,  ...,  2.1926e-02,\n",
      "          5.0224e-04,  9.5193e-03],\n",
      "        [-2.0808e-02, -2.5681e-02, -5.0310e-06,  ...,  2.4961e-02,\n",
      "          4.6822e-03, -7.2651e-03],\n",
      "        ...,\n",
      "        [ 5.2342e-03,  2.7472e-02, -3.2541e-03,  ..., -2.0958e-02,\n",
      "         -2.2879e-02, -3.3176e-03],\n",
      "        [-2.2995e-02, -1.0419e-02,  2.3571e-02,  ...,  2.6170e-02,\n",
      "         -3.1458e-03, -1.7611e-02],\n",
      "        [ 2.9952e-04,  2.7372e-02,  6.7301e-04,  ...,  2.0804e-02,\n",
      "         -9.3636e-03,  2.4929e-02]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0124, -0.0094,  0.0178,  0.0116,  0.0083,  0.0060,  0.0219, -0.0040,\n",
      "        -0.0234, -0.0182, -0.0214, -0.0026,  0.0048,  0.0209,  0.0225, -0.0088,\n",
      "         0.0128, -0.0191,  0.0223, -0.0114, -0.0192, -0.0051, -0.0066,  0.0024,\n",
      "         0.0028,  0.0252, -0.0233, -0.0179, -0.0073, -0.0001, -0.0128,  0.0176,\n",
      "        -0.0162, -0.0191,  0.0063,  0.0102,  0.0065, -0.0117, -0.0069, -0.0143,\n",
      "        -0.0265,  0.0070, -0.0134, -0.0252, -0.0223, -0.0240,  0.0010,  0.0243,\n",
      "        -0.0044,  0.0077, -0.0077,  0.0108, -0.0016,  0.0148, -0.0270,  0.0235,\n",
      "         0.0013, -0.0116,  0.0028, -0.0249,  0.0204, -0.0220, -0.0091,  0.0279,\n",
      "        -0.0008,  0.0270,  0.0152, -0.0216, -0.0086,  0.0082, -0.0129, -0.0116,\n",
      "        -0.0061, -0.0276, -0.0023, -0.0171,  0.0221,  0.0199,  0.0153,  0.0199,\n",
      "         0.0047,  0.0136, -0.0059,  0.0143,  0.0188, -0.0187,  0.0197, -0.0104,\n",
      "         0.0105, -0.0154,  0.0267,  0.0016,  0.0015,  0.0227, -0.0224, -0.0158,\n",
      "        -0.0201,  0.0185,  0.0244,  0.0245, -0.0175, -0.0087,  0.0238,  0.0165,\n",
      "         0.0014,  0.0034,  0.0194, -0.0157,  0.0202,  0.0059, -0.0126, -0.0082,\n",
      "        -0.0195,  0.0010,  0.0218, -0.0082,  0.0113, -0.0234,  0.0239,  0.0218,\n",
      "         0.0179, -0.0103, -0.0258, -0.0147,  0.0066, -0.0174,  0.0025, -0.0226],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0545, -0.0839, -0.0055,  ...,  0.0191, -0.0764, -0.0592],\n",
      "        [-0.0124,  0.0820,  0.0732,  ..., -0.0321, -0.0122, -0.0009],\n",
      "        [ 0.0486,  0.0559, -0.0713,  ..., -0.0845,  0.0159, -0.0527],\n",
      "        ...,\n",
      "        [ 0.0395, -0.0171,  0.0388,  ...,  0.0506, -0.0158,  0.0134],\n",
      "        [-0.0535, -0.0314,  0.0434,  ...,  0.0677,  0.0751,  0.0874],\n",
      "        [-0.0504,  0.0262,  0.0743,  ...,  0.0551,  0.0548, -0.0463]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0661, -0.0559, -0.0847, -0.0449,  0.0293,  0.0308, -0.0102,  0.0680,\n",
      "         0.0721, -0.0703], device='cuda:0', requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "A continuacion ingrese los parametros del modelo\n",
    "\n",
    "# Vision Transformer\n",
    "Model\n",
    "> \n",
    "```ViT-Base ViT-Large ViT-Huge\n",
    "    Layers Hidden size D 12 768\n",
    "    24 1024 32 1280\n",
    "    MLP size Heads\n",
    "    Params\n",
    "    3072 12 86M 4096 16 307M 5120 16 632M\n",
    "```\n",
    "\n",
    "'''\n",
    "img_size   = 32\n",
    "patch_size = 4\n",
    "embed_dim  = 768\n",
    "num_heads  = 8\n",
    "ff_dim     = 1280\n",
    "num_layers = 6\n",
    "dropout    = 0.1  \n",
    "\n",
    "# num_patches = (img_size // patch_size) ** 2\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "model = VisionTransformer(\n",
    "    img_size=img_size,\n",
    "    patch_size=patch_size,\n",
    "    embed_dim=embed_dim, \n",
    "    num_heads=num_heads, \n",
    "    ff_dim=ff_dim, \n",
    "    num_layers=num_layers, \n",
    "    dropout=dropout,\n",
    "    batch_first=True,\n",
    "    num_classes=10\n",
    ").to(device)\n",
    "\n",
    "\n",
    "print(\"Parametros del modelo:\", list(model.parameters()))\n",
    "\n",
    "# Definimos funciones de loss y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4)\n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "try:\n",
    "    model = torch.compile(model)\n",
    "except Exception as e:\n",
    "    print(\"Se produjo error durante la compilación:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de parámetros: 89.08 millones\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model: nn.Module) -> int:\n",
    "    \"\"\"\n",
    "    Count the number of trainable parameters in a PyTorch model.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The PyTorch model.\n",
    "\n",
    "    Returns:\n",
    "        int: The total number of trainable parameters.\n",
    "    \"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad) / 1_000_000\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Número de parámetros: {:.2f} millones\".format(count_parameters(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/98 [00:00<?, ?it/s]W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT forward D:\\Users\\juanp_schamun\\AppData\\Local\\Temp\\ipykernel_22264\\3036822529.py line 26 \n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1031 16:27:02.390000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT forward D:\\Users\\juanp_schamun\\AppData\\Local\\Temp\\ipykernel_22264\\2230262351.py line 53 \n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1031 16:27:02.505000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT forward D:\\Users\\juanp_schamun\\AppData\\Local\\Temp\\ipykernel_22264\\2230262351.py line 75 \n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1031 16:27:02.582000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT forward D:\\Users\\juanp_schamun\\AppData\\Local\\Temp\\ipykernel_22264\\3349205134.py line 7 \n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"d:\\Users\\juanp_schamun\\AppData\\Local\\anaconda3\\envs\\ViT\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1031 16:27:05.523000 22264 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "loss 1.62457: 100%|██████████| 98/98 [00:50<00:00,  1.92it/s]\n",
      "loss 1.36957: 100%|██████████| 98/98 [00:44<00:00,  2.21it/s]\n",
      "loss 1.07185: 100%|██████████| 98/98 [00:46<00:00,  2.10it/s]\n",
      "loss 0.84460: 100%|██████████| 98/98 [00:43<00:00,  2.25it/s]\n",
      "loss 0.83266: 100%|██████████| 98/98 [00:44<00:00,  2.22it/s]\n",
      "loss 0.81484: 100%|██████████| 98/98 [00:44<00:00,  2.22it/s]\n",
      "loss 0.80490: 100%|██████████| 98/98 [00:44<00:00,  2.22it/s]\n",
      "loss 0.67623: 100%|██████████| 98/98 [00:44<00:00,  2.21it/s]\n",
      "loss 0.63194: 100%|██████████| 98/98 [00:44<00:00,  2.21it/s]\n",
      "loss 0.65318: 100%|██████████| 98/98 [00:44<00:00,  2.21it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, train_loader,test_loader,criterion,optimizer, device)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    trainer.train_model(use_amp=True)\n",
    "    \n",
    "    #scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img = train_loader.dataset[1][0]\n",
    "img = img.unsqueeze(0)\n",
    "img = img.to(device).float()\n",
    "print(img.shape)\n",
    "outputs = model(img)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:09<00:00,  2.07it/s]\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, data_loader):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(data_loader):\n",
    "            images = images.to(device).float()\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "    \n",
    "    accuracy  = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall    = recall_score(y_true, y_pred, average='macro')\n",
    "    f1        = f1_score(y_true, y_pred, average='macro')\n",
    "    \n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Evaluar el modelo\n",
    "accuracy, precision, recall, f1 = evaluate_model(model, test_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73\n",
      "Precision: 0.74\n",
      "Recall: 0.73\n",
      "F1 score: 0.73\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def visualize_classification(model, data_loader, class_names, num_images=16):\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate((data_loader)):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images // 4, 4, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'True: {class_names[labels[j]]}\\nPred: {class_names[preds[j]]}')\n",
    "                img = inputs[j].cpu().numpy().transpose((1, 2, 0))\n",
    "                img = img * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]  # Unnormalize\n",
    "                img = np.clip(img, 0, 1)\n",
    "                ax.imshow(img)\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    return\n",
    "\n",
    "\n",
    "meta = unpickle('./data/cifar-10-batches-py/batches.meta')\n",
    "class_names = meta[b'label_names']\n",
    "visualize_classification(model, test_loader, class_names, num_images=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3122, -6.3257, -0.3149,  ..., 11.1505, -7.7784, -3.5425],\n",
      "        [-3.1856, -0.8082,  3.9800,  ..., -1.3047, -4.9215, -3.1113],\n",
      "        [-3.9336, -4.9216, -0.1412,  ..., -0.2647, -2.5279, -1.1237],\n",
      "        ...,\n",
      "        [ 2.9305, -3.1320, -1.6663,  ..., -1.0756,  8.1021, -2.2093],\n",
      "        [ 0.6892,  7.0540, -2.7532,  ..., -3.1516,  1.9321,  1.8602],\n",
      "        [ 0.0129, -5.4126, -0.5207,  ..., -0.5005, -1.4828, -5.0488]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# get some random training images\n",
    "with torch.no_grad():\n",
    "    dataiter = iter(test_loader)\n",
    "    images, labels = next(dataiter)\n",
    "    inputs = images.to(device)\n",
    "    outputs = model(inputs)\n",
    "    # outputs = torch.max(outputs, 1)\n",
    "    print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 6, 3, 2, 7, 7, 1, 0, 1, 7, 4, 1, 1, 9, 4, 5, 5, 4, 5, 7, 6, 9, 7, 2,\n",
       "        8, 5, 8, 8, 6, 0, 5, 0, 1, 4, 5, 0, 8, 7, 1, 9, 5, 8, 1, 0, 0, 3, 4, 9,\n",
       "        5, 2, 0, 1, 7, 2, 1, 9, 0, 9, 3, 2, 0, 1, 8, 3, 4, 4, 5, 7, 7, 8, 2, 1,\n",
       "        3, 6, 5, 0, 9, 8, 9, 5, 7, 2, 1, 5, 3, 0, 2, 2, 7, 8, 7, 1, 5, 5, 5, 5,\n",
       "        8, 1, 8, 9, 3, 6, 6, 4, 7, 6, 1, 4, 0, 8, 2, 1, 5, 4, 2, 6, 7, 9, 7, 8,\n",
       "        2, 1, 6, 7, 8, 9, 1, 3, 0, 7, 5, 6, 5, 2, 0, 7, 6, 5, 1, 1, 1, 6, 7, 3,\n",
       "        8, 6, 7, 1, 9, 0, 3, 2, 2, 0, 5, 0, 9, 7, 7, 4, 9, 7, 7, 1, 2, 1, 1, 5,\n",
       "        9, 1, 5, 0, 1, 3, 0, 0, 9, 3, 5, 7, 5, 5, 4, 4, 2, 5, 0, 0, 5, 1, 9, 8,\n",
       "        8, 8, 3, 0, 5, 9, 4, 8, 2, 5, 2, 2, 5, 8, 5, 9, 7, 5, 2, 9, 6, 2, 5, 0,\n",
       "        1, 5, 9, 1, 1, 1, 2, 2, 8, 6, 0, 0, 8, 6, 2, 6, 1, 7, 1, 4, 8, 4, 0, 7,\n",
       "        4, 9, 7, 0, 5, 3, 4, 8, 2, 1, 7, 3, 6, 0, 5, 5, 8, 5, 9, 7, 2, 7, 7, 6,\n",
       "        0, 9, 2, 5, 7, 7, 7, 9, 5, 1, 0, 4, 8, 9, 8, 9, 0, 5, 9, 6, 1, 2, 8, 3,\n",
       "        1, 5, 9, 0, 3, 0, 1, 0, 9, 5, 6, 5, 2, 1, 5, 3, 8, 0, 5, 9, 4, 9, 9, 5,\n",
       "        7, 0, 7, 9, 2, 9, 3, 1, 6, 2, 5, 8, 9, 1, 3, 2, 9, 6, 2, 6, 1, 1, 7, 7,\n",
       "        0, 7, 8, 9, 9, 4, 5, 5, 5, 4, 5, 9, 2, 9, 4, 4, 3, 6, 7, 9, 4, 4, 4, 8,\n",
       "        8, 0, 3, 2, 1, 5, 2, 5, 0, 3, 1, 5, 3, 3, 5, 0, 9, 0, 3, 4, 2, 2, 6, 9,\n",
       "        9, 9, 9, 0, 9, 1, 8, 6, 4, 6, 9, 0, 9, 2, 8, 4, 7, 9, 7, 0, 8, 6, 2, 1,\n",
       "        7, 5, 1, 4, 3, 7, 5, 6, 9, 1, 7, 6, 4, 0, 7, 1, 6, 7, 9, 2, 0, 3, 5, 5,\n",
       "        2, 7, 5, 0, 5, 2, 3, 8, 6, 0, 3, 9, 8, 8, 2, 3, 2, 9, 5, 5, 0, 4, 3, 1,\n",
       "        6, 8, 8, 6, 8, 2, 4, 8, 3, 7, 2, 8, 0, 1, 3, 5, 9, 4, 2, 0, 0, 7, 1, 2,\n",
       "        9, 7, 0, 9, 9, 6, 3, 8, 2, 4, 5, 0, 7, 9, 5, 8, 7, 8, 3, 6, 0, 2, 9, 7,\n",
       "        9, 3, 9, 4, 8, 8, 1, 5], device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.max(1)[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ViT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
